:time_estimate: 5

= Test Bootc Containers With Bootc Install

_Estimated reading time: *{time_estimate} minutes*._

Objective::
Deploy a local bootc container image in a local VM.

WARNING: Work in progress

== PROVISORY OUTLINE

* Use a preexisting VM (or create a new one using package mode) and use bootc install and/or system-reinstall-bootc to replace the OS on that VM with a bootc container image.
* Optional: use Podman Desktop (or just macadam) as a simpler way of testing bootc container images with local VMs, for the benefit of non-Linux developers
* Try to do it without a remote container registry. If it's too cumbersome, reorder topics so this lab and its presentation come the last in the course
* This lab is NOT trying to emulate provisioning physical devices using local VMs, but to boot a VM from a bootc container image the quickest/simplest way possible, for inner loop testing of new images.


== Before you Begin

You need a _development machine_ running RHEL, to which you have access using an unprivileged user account.

These instructions were tested on RHEL 10.0 but should work with minimal or no change on and newer and older RHEL releases, since 9.6.

If you are using the course classroom, you will log in on the `workstation` VM as the user `student` with password `student`. If not, please adapt the instructions to your test environment.

Make sure you verified your test environment by following the xref:ch1-intro:s3-prereqs-lab.adoc[first lab] of this course.

== Instructions

1. Prepare to start this activity by checking that you have the outcomes from previous activities.

.. If needed, create a local clone of the sample code repository of this course, but do NOT enter its directory.
Stay on your home directory to start this lab.
+
[source,subs="verbatim,quotes"]
--
$ *cd*
$ *git clone https://github.com/RedHatQuickCourses/rhde-bootc-samples.git*
Cloning into 'rhde-bootc-samples'...
...
--
+
////
// Not needed for this lab
.. If needed, login to your private registry.
+
[source,subs="verbatim,quotes"]
--
$ *podman login -u student -p redhat registry.lab.example.com:5000*
Login Succeeded!
--
////

.. Verify that you have a bootc container image named `localhost/httpd-bootc` in your local container storage.
If you do not, please perform the xref:ch2-build:s2-podman-lab.adoc[previous lab] which builds that image.
+
[source,subs="verbatim,quotes"]
--
$ *podman image list | grep httpd-bootc*
localhost/httpd-bootc                            latest      dc263eabb8d7  18 hours ago  1.56 GB
--

.. Verify that you have access to libvirt though its session interface.
If you do not, please perform the preparation tasks from the xref:ch1-intro:s3-prereqs-lab.adoc[first lab].
+
[source,subs="verbatim,quotes"]
--
$ *virsh list --all*
 Id   Name   State
--------------------

--
+
NOTE: It is fine if you have some local VMs on your system, as long as there isn't a VM named `bootc-test`.

2. Prepare scripts and configuration files you will use to automate creation of a test VM.

.. Copy your bootc container image to a local directory, in a format that Anaconda can use as its installation source.
+
[source,subs="verbatim,quotes"]
--
$ *mkdir temp-bootc*
$ *skopeo copy containers-storage:localhost/httpd-bootc oci:temp-bootc/oci:httpd-bootc*
--

.. Create a working directory and copy the sample files to it.
+
[source,subs="verbatim,quotes"]
--
$ *mkdir temp-test-vm*
$ *cp rhde-bootc-samples/bootc-install/inst.ks temp-test-vm* 
$ *cp rhde-bootc-samples/bootc-install/virt-install.sh temp-test-vm*
$ *cd temp-test-vm*
--

.. Review the example kickstart file named `inst.ks`.
+
It is a sandard RHEL Anaconda configuration for unatenneded installation, which uses a number of features:
+
... A virtiofs mount, in a `%pre` script, to get the contents of your bootc container image.
... The `ostreecontainer` command, to set a bootc container iamge as the installation source.
... A `%post` script which creates an initial user, with a known password and SSH key.
... Also in the `%post` script, it sets an initial hostname, which helps you identify your test VM and recognize it didn't went into any day-2 configuration or onboarding process yet.
+
// Could use callouts, and embed them into the example file as comments.
+
[source,subs="verbatim,quotes"]
--
include::1@samples:bootc-install:example$inst.ks[]
--

.. Create an SSH key for use with your test VM and embed it in the kickstart file.
+
[source,subs="verbatim,quotes"]
--
$ *ssh-keygen -N '' -f edge-key -C 'initial key for edge devices'*
Generating public/private rsa key pair.
$ *SSH_PUB_KEY=$( cat edge-key.pub )*
$ *sed -i "s|REPLACE_WTH_SSH_PUB_KEY|$SSH_PUB_KEY|" inst.ks*
--

.. Review the `virt-install.sh` script which creates a test VM.
+
It is designed to be console-friendly, so you do not need to switch to a graphical console or remote desktop session just to view the test VM boot screens, and to NOT require access to a remote container registry, by using the following features of libvirt:
+
... User mode networking with the Passt provider and port-forwarding to enable network connections from your _development machine_ to services running inside the test VM.
... Direct kernel loading (the `--location` option) to grab the Linux kernel and initial RAM disk from a remote HTTP server.
... Injection of a custom kickstart file, so RHEL installation runs unattended.
... A virtiofs device (the `--memorybacking` and `--filesystem` options) to enable access to a installation source without remote network servers but from local host files.
... A serial console, so boot messages display in the current terminal, which could be an SSH session.
+
[source,subs="verbatim,quotes"]
--
include::1@samples:bootc-install:example$virt-install.sh[]
--

3. Create a local virtual machine (VM) from your bootc container images, using the provided scripts.

.. Run the installation script.
+
You could use it from a machine you do NOT have root access, as long as someone already installed Libvirt and its tooling.
+
[source,subs="verbatim,quotes"]
--
$ *bash virt-install.sh*
--

.. Observe your test VM boot screen and RHEL Anaconda messages, as it boots, installs RHEL, and reboots into the newly installed system.
+
The following messages indicate when Anaconda is done preparing the system and starts reading your bootc container image:
+
[source,subs="verbatim,quotes"]
--
...
Setting up the installation environment
.
Configuring storage
Creating disklabel on /dev/vda
Creating xfs on /dev/vda3
Creating xfs on /dev/vda2
Creating biosboot on /dev/vda1
.
Running pre-installation scripts
.
Running pre-installation tasks
.
Installing the software
Deployment starting: /mnt/host-var-srv/oci:httpd-bootc
...
--

.. If all goes well, you will see a message that states you VM (_domain_ or _guest_ in libvirt's jargon) was created, but may not see its RHEL login screen.
+
[source,subs="verbatim,quotes"]
--
...
Domain creation completed.
Restarting guest.
Running text console command: virsh --connect qemu:///session console test-bootc
Connected to domain 'test-bootc'
Escape character is ^] (Ctrl + ])
--

.. Detach from the VM console, by pressing kbd:[Ctrl+\]], and start a SSH session to your test VM.
+
[source,subs="verbatim,quotes"]
--
$ *ssh -i edge-key -p 8022 core@127.0.0.1*
[core@bootc-test ~]$
--

.. If there were issues, before you go back to fix your kickstart and script files, stop and destroy your test VM.
+
IMPORTANT: Do NOT run these commands if all went well.
You will still need your test VM in the next steps.
+
[source,subs="verbatim,quotes"]
--
$ *virsh destroy bootc-test*
Domain 'bootc-test' destroyed
$ *virsh undefine bootc-test --remove-all-storage*
Domain 'bootc-test' has been undefined
Volume 'vda'(/home/student/.local/share/libvirt/images/bootc-test.qcow2) removed.
--


4. Verify that your test VM was actually provisioned from the contents of your bootc container iamage.

.. Verify that your test VM contains an active bootc deployment.
+
The password of the `core` user (for `sudo`) is `redhat123`.
+
[source,subs="verbatim,quotes"]
--
$ *sudo bootc status*
‚óè Booted image: oci:/mnt/host-var-srv/oci:httpd-bootc
        Digest: sha256:5ba977e2a75507b722535b21ae40f794176b61c63754e916a0531a6f9f76b894
       Version: 10.0 (2025-08-11 20:34:32.003406539 UTC)
--

.. Verify that your test VM has an active Apache Web Server.
+
[source,subs="verbatim,quotes"]
--
$ *rpm -q httpd*
httpd-2.4.63-1.el10.x86_64
$ *systemctl is-active httpd*
active
--

.. Verify that your test VM contains the files of your single-page web application.
+
[source,subs="verbatim,quotes"]
--
$ *cat /var/www/html/index.html*
This would be the HTML and Javascrit code of you single-page web application.
--

.. Exit your SSH session and return to your _development machine_ shell.
+
[source,subs="verbatim,quotes"]
--
$ *exit*
logout
Connection to 127.0.0.1 closed.
--

5. Verify that your _development machine_ can access the singe-page web app running in the test VM.

.. Verfify that you get, though the libvirt port-forward tunnel, the contents of your singe-page web app.
+
[source,subs="verbatim,quotes"]
--
$ *curl 127.0.0.1:8080*
This would be the HTML and Javascrit code of you single-page web application.
--

.. If all went well, stop and destroy your test VM to conserve resources.
If you want to keep it, you must edit your scripts to change the name of the VM you will create on the next steps.
+
[source,subs="verbatim,quotes"]
--
$ *virsh destroy bootc-test*
Domain 'bootc-test' destroyed
$ *virsh undefine bootc-test --remove-all-storage*
Domain 'bootc-test' has been undefined
Volume 'vda'(/home/student/.local/share/libvirt/images/bootc-test.qcow2) removed.
--
+
NOTE: You could reuse the same test VM, and use the `bootc` command to switch it to another container image from a remote container registry, but for now let's ensure that we get a brand new test VM, without any state left over from previous tests.

6. Create another test VM, this time from the `webapp-bootc` container image [ Expect it to fail because of SELinux labels ]

.. Return to your home directory copy a second local container image to your OCI directory.
+
[source,subs="verbatim,quotes"]
--
$ *cd*
$ *skopeo copy containers-storage:localhost/webapp-bootc oci:temp-bootc/oci:webapp-bootc*
--

.. Change the kickstart script on your temporary directory to refer to the second bootc container image.
+
[source,subs="verbatim,quotes"]
--
$ *cd temp-test-vm*
$ *sed -i '1,$ s/httpd-bootc/webapp-bootc/g' inst.ks*
GRAB OUTPUT
--

.. Create a new test VM, using the kickstart script you just changed.
+
Make sure it reports using the `webapp-bootc` container iamge as its installation source.
+
[source,subs="verbatim,quotes"]
--
$ *bash virt-install.sh*
...
Installing the software
Deployment starting: /mnt/host-var-srv/oci:webapp-bootc
...
--

.. When your new test VM finish starting, detach from its VM console by pressing kbd:[Ctrl+\]], and start a SSH session to your new test VM.
+
[source,subs="verbatim,quotes"]
--
$ *ssh -i edge-key -p 8022 core@127.0.0.1*
[core@bootc-test ~]$
--

7. Verify that your new VM is NOT working as expect, and troubleshoot it.
+
[ It worked :-( despite the SELinux labels being wrong AND it being on eforcing mode ]

.. TBD
+
[source,subs="verbatim,quotes"]
--
$ **
--

99. Delete your temporary directories, especially the large OCI directory which now contains multiple GB bootc container images.

.. TBD

99. DELETE THIS AFTER TESTING ALL STEPS ABOVE
+
[source,subs="verbatim,quotes"]
--
### SCRATCHPAD FOR TESTING COMMANDS
$ cd # run from $HOME
$ mkdir temp-bootc
$ skopeo copy containers-storage:localhost/httpd-bootc oci:temp-bootc/oci:httpd-bootc
...
Writing manifest to image destination
## this copy is slow :-(
$ cp rhde-bootc-samples/bootc-install/inst.ks temp-bootc
$ cp rhde-bootc-samples/bootc-install/inst.ks .
## which of the previous two?
$ cp rhde-bootc-samples/bootc-install/virt-install-bootc.sh .
$ bash virt-install-bootc.sh
...
Domain creation completed.
Restarting guest.
Running text console command: virsh --connect qemu:///session console bootc-test
Connected to domain 'bootc-test'
Escape character is ^] (Ctrl + ])
## leave the installer, after reboot and seeing a login prompt
$ ssh -i edge-key -p 8022 127.0.0.1
## see password on the kickstart, and the misleading hostname -- find the %post that sets a hostname!
## can I download the RHEL DVD from classroom to workstation?
## Something is not working with the text console and text login.
## Can I use a relative path for --filesystem  ?
--

.. Alternativelly, try a RHEL cloud image (which I would have to add to the HOL019 classroom).
+
[source,subs="verbatim,quotes"]
--
### SCRATCHPAD FOR TESTING COMMANDS
$ *virt-istall*
--

== What's Next

The next chapter demonstrates how to publish bootc container images on OCI container registries, so they can be used to provision physical systems, cloud instances, or virtual machines on the data center.