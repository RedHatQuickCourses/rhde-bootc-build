:time_estimate: 7

= Strategies for Building Bootc Container Images

_Estimated reading time: *{time_estimate} minutes*._

Objective::
Present common issues, recomendations, and coding idioms for building bootc container images.

WARNING: Work in progress

Now that you know now to build a bootc container image from a containerfile, and you also know that most things you would do in the containerfile for application containers also apply to containerfiles for bootc containers, it's time to consider what you could do in containerfiles for bootc images that you woud NOT usually for application containers.

== Approaches for appliances versus enforcing separation of concerns

Previous examples followed an appliance approach: application code, configurations, and initial data are embedded in a bootc container image.

This may be a good approach for edge devices which serve a single purpose and are not likely to be repurposed very often.
It also simplifies day-2 configuration of image mode systems.

Some organizations prefer to enforce a strict separation of concerns, where an infrastructure team manages the lifecycle of operating systems while a different teams manage the lifecycle of applications.

A way of implementing this approach is to keep applications outside of bootc container images, in their own application container images, and optionally link those applications to bootc images using bounded containers[ADD LINK].

Whatever your approach, image mode enables reducing the effort and time to perform day-1 and day-2 configuration of an edge device.

== System settings on containerfiles

Configuration of linux system happens mostly through text files stored in the `/etc` directory.
This is important for bootc containers because, when you build them, only changes to files become part of the resulting container image.
If your containerfile performs actions that make no changes to files, such as setting a kernel parameter by writing to `/proc`, those actions have no effect on your bootc container images.

Most system configuration commands from RHEL already perform their work by changing files, for example `dnf install` and `systemctl enable`, so they can be used in containerfiles without issues.

A few commands actually communicate with a system service, using one interprocess communication (IPC) channel and, if used in a containerfile, they would try to affec the host performing the build, but would have no effect in the resulting container image. 

If you need such commands, you must find how their services actually store configuration data and find a way of affecting that store directly, without using IPC or without trying to affect the current host system.
For example, the `firewall-cmd` command communicates with the Firewal daemon to change the kernel netfilter tables directly, but there's the `firewall-offline-cmd` command which only stores configuration changes.

Some commands affect data outside files, for example installing a Grub bootloader in the primary disk partition table.
Instead of running such commands on your containerfile, you create bootc configuration files.

When your bootc container image is installed in an image mode system, the bootc utility takes care of altering the bootloader configuration on its root disk.
For example, the `/usr/lib/bootc/kargs.d` directory provides kernel arguments which bootc adds to the kernel command line of its system Grub menu.

You may find, in a containerfile for a bootc container image, some commands and files which you wouldn't find in a containerfile for an application, but which are just standard Linux configuration files.
For example, files in the `/usr/lib/sysctl.d` directory configure kernel parameters, mimicking the `/proc` tree structure.

Think about your containerfiles as configuring a system so those settings remain persistent, and are in effect for the next time you boot a system. 

=== Configuration using drop files

Legacy UNIX services usually support a single configuration file.
You can (sometimes) set the path to this file, but you must provide a complete configuration file.

This sometimes becomes problematic during version updates, where the syntax of the configuration file changes.
It also makes configuration management harder, because you must track multiple small changes, made to different sections of a single large file.

More modern Linux services usualy support a search path for configuration files, and multiple files per directory.
They enable you to provide self-contained, small configuration files which set only the parameters you want, while relying on whatever defaults were provided by the system.
These small files are called _drop files_.

Not only you have fewer changes, which are easier to track in a version control system, but you can perform version updates and frequently keep using your configuration files form earlier versions unchanged.
It also enables reusing the same files among different systems, for example: some systems get drop files A, B, and C, while other systems get drop files A, B, and D.

The `/usr/lib/sysctl.d` directory is an example of a directory which contains drop files.
On the other hand, our single page web application example made changes to a legacy, monolithic configuration file `/etc/httpd/conf/httpd.conf`, but the Apache Web Server supports drop files in the `/etc/httpd/conf.d` directory, which we could have used.

Many of your issues will happen because you're using legacy configurations, which were not updated to align with current recommendations and features of current versions of Linux system and network services.

=== Immutable vs configurable system settings

Modern Linux services include two system directories to their configuration search path, one in `/etc`, and the other in `/usr/lib`.
Changes to either of them result in the same outcome, but remember the first is a writable directory in image mode systems, while the second is read-only.

The recommendation is that, whenever possible, containerfiles for bootc container images make changes to configuration files in `/usr/lib` so these changes are part of the image and it is easier to track which changes were made on day-2.

For most Linux services, settings in `/etc` override settings in `/usr/lib` so you are NOT locking the system into a fixed configuration, but you are perserving a pristine copy of your intended configurations.
If you need, just remove the local changes made in '/etc'.

=== SElinux and bootc

Bootc takes care of most things that must run at either installation or update time, for example relabeling files for the correct SELinux context label.
Just remember to provide the required SELinux policies as part of your bootc container image.

Application containers usually do not care about SELinux, because container engines run them within a single per-container context, based on MCS labeling.
But an image mode system, once installed from a bootc container image, enforces standard SELinux policies and contexts.

=== One time Systemd units

Sometimes you need to add custom code which you intend to run only once, during installation, or at every boot.
This is a standard Systemd feature, so you just add Systemd unit files to you bootc container image, and of course also add the scripts or binaries those units reference.

== The need for system testing

After you build a containerfile which includes system settings, you can verify that the correct configuration files exist in your bootc container image by running it with Podman.
But you CANNOT verify that these settings are actually in effect, nor that they produced the expected outcomes.

Remember that container engines run application containers with their current host kernel and system settings.
The kernel, system services, and settings inside a bootc container image are simply ignored when run from a container engine.

== What's Next

The next activity builds a bootc container image which varied system settings, demonstrates that these settings are stored in the image but not active in a container. The next chapter shows how to perform system testing of bootc container images by installing them in a local VM.
